# Explainable_image_classification_SMER

## SMER+LLM for Explainable Image Classification ğŸš€
This repository contains the code and experiments from our diploma project, which focuses on enhancing explainability in image classification. The project integrates the SMER (Sequential Masking for Evaluating Relevance) method with Large Language Models (LLMs) to provide high-fidelity, object-level explanations.

Overview
SMER+LLM Workflow: Combines SMER's direct evaluation of region importance with the interpretative power of LLMs to generate precise bounding boxes and coherent visual explanations. ğŸ”
Method Comparisons: Includes implementations and evaluations of alternative explanation methods such as LIME and MoRF (Most Relevant First). These methods are applied both directly on images and using a ResNet classifier for a comprehensive comparison. âš–ï¸
Quantitative Evaluation: Experiments employ the AOPC (Average Output Probability Change) metric to measure the impact of removing influential features, validating the reliability of our approach. ğŸ“Š
Qualitative Evaluation: Visual comparisons demonstrate that our SMER+LLM workflow delivers more coherent and interpretable object-level explanations compared to existing techniques. ğŸ¨
Reproducibility: All code, data processing scripts, and detailed instructions for reproducing the results are included. ğŸ”„
Getting Started
For complete setup instructions, experiment details, and how to replicate our evaluations, please refer to the README.md.

Contributions, feedback, and collaborations are highly welcome. Let's make explainable AI even more exciting! ğŸ‰

Enjoy exploring the repository!
